TODO:
    Start from hovering at gate center. Set episode length to 500, let it hover till the end.
    Also do imitation learning, use PID (for robustness) with attitude output as teacher policy, run simultaneously and compare output.

Train: lesson 1.0 Hover at gate
    time: Jun 10 06:07
    n_envs: 20
    steps: 2 * 400000
    duration: 20min
    changes: hover
    result: flying to gate but unstable
    comments: param works, keep training

Train: lesson 1.1
    time: Jun 10 07:21
    n_envs: 20
    steps: 6 * 400000
    duration: 38min
    changes: 
    result: fly and hover half meter in front of the gate, will do 
    comments: move to next lesson

Train: lesson 2.1 with obstacles
    time: Jun 10 07:21
    n_envs: 20
    steps: 4 * 400000
    duration: 27min
    changes: 
    result: avoid obstacles sometimes, still not going into the gate
    comments: increase k_gate

Train: lesson 2.2
    time: Jun 10 12:02
    n_envs: 20
    steps: 2 * 400000
    duration: 18min
    changes: +k_gate -k_gate_pos -k_obst -k_obst_d ++k_success
    result: afraid of going through the gate
    comments: decrease r, increase k_gate

Train: lesson 2.3
    time: Jun 10 12:37
    n_envs: 20
    steps: 2 * 400000
    duration: 18min
    changes: +k_gate -r
    result: still afraid, but better collision avoidance
    comments: try next lesson in racing environment

Train: lesson 3.1 Racing environment with imitation learning
    n_envs: 20
    steps: 6 * 400000
    duration: 38min
    changes: +k_gate -r
    result: still stop in front of the gates?? why?
    comments: perhaps caused by r_center 

Train: lesson 3.2 Racing environment with imitation learning
    n_envs: 20
    steps: 6 * 400000
    duration: 38min
    changes: -r_center
    result: still stop
    comments: 

Train: lesson 3.3 Racing environment with imitation learning
    n_envs: 20
    steps: 6 * 400000
    duration: 38min
    changes: +k_vel +k_imit +k_success
    result: just won't get in the fxxking gate
    comments: I might just try start from scratch

Train: lesson 4.0 Racing environment with imitation learning from scratch
    n_envs: 20
    steps: 6 * 400000
    duration: 56min
    changes: recreate model
    result: works pretty nice! able to pass four gates! However directly crashes on original takeoff position.
    comments: I'll add original start position and retrain a model.

Train: lesson 4.1 Racing environment with imitation learning from scratch
    n_envs: 20
    steps: 12 * 400000
    duration: 86min
    changes: add takeoff position, + k_vel
    result: moving faster, but not stable 
    comments: 

Train: lesson 4.2 Racing environment with random gate
    n_envs: 20
    steps: 6 * 400000
    duration: 38min
    changes: remove imitation learning, add random gates
    result: 
    comments: 

Train: lesson 4.3 Racing environment Level 2 
    n_envs: 20
    steps: 2 * 400000
    duration: 17min
    changes: remove imitation learning, add random gates
    result: working fine observed success rate over 50%, avg 6s
    comments: keep going
    
Train: lesson 4.4 Racing environment Level 2 
    n_envs: 20
    steps: 2 * 400000
    duration: 17min
    changes: add finish reward, remove rand init, +k_vel, but flip k_vel at 3rd gate
    result: rush even longer after passing 3rd gate
    comments: add more panalty for 3rd gate
    
Train: lesson 4.5 Racing environment Level 2 (reset to 4.3)
    n_envs: 20
    steps: 3 * 400000
    duration: 17min
    changes: +k_vel, flip k_vel at 3rd and 4rd gate, and add panalty
    result: success rate high, but too fast at first 2 gates. and stil rushing to far
    comments: slower

Train: lesson 4.6 Racing environment Level 2 (reset to 4.3)
    n_envs: 20
    steps: 4 * 400000
    duration: 34min
    changes: -k_vel, with gate 3 special penalty
    result: still too fast
    comments: keep slowing down

Train: lesson 4.7 Racing environment Level 2 (reset to 4.3)
    n_envs: 20
    steps: 4 * 400000
    duration: 34min
    changes: -k_vel, with heavier penalty, lap time based finish reward
    result: it worked! finally not rushing too much, not stable enough
    comments: I say keep doing this for 1M

Train: lesson 4.8 Racing environment Level 2
    n_envs: 20
    steps: 2 * 400000
    duration: 17min
    changes: -k_vel, with heavier penalty, lap time based finish reward
    result: success rate increased a bit
    comments: keep going

Train: lesson 4.9 Racing environment Level 2
    n_envs: 20
    steps: 12 * 400000
    duration: 100min
    changes: add 3rd gate panalty 0.2m earlier
    result: 3rd gate finally normal, just like our mpcc trajectory. but first gate not stable
    comments: I just realized sensor range is set to infiniteï¼Œ need more train?
              With infinite sensor range only 5/10, 5.91s; with 0.5m sensor range only 2/10
              should add hard velocity penalty box 0.5m before the gates
              Additionally, is it a good idea to just apply mpcc cost as reward?

Train: lesson 4.10 Racing environment Level 2 (0.5m sensor range)
    n_envs: 20
    steps: 6 * 400000
    duration: 40min
    changes: add vel penalty before each gate, -y_exceed
    result: much slower, trajectory makes more sense, but adaptability still bad
    comments: positive velocity reward in between gates, +k_crash

Train: lesson 4.11 Racing environment Level 2 (0.5m sensor range)
    n_envs: 20
    steps: 6 * 400000
    duration: 38min
    changes: vel reward and penalty at different phases, add some crash penalty
    result: trajectory looks beautiful, but neither stable nor fast
    comments: 

Train: lesson 4.12 Racing environment Level 2 (0.5m sensor range)
    n_envs: 20
    steps: 6 * 400000
    duration: 38min
    changes: add gate reward, decrease success reward, loosen 2nd gate exceed penalty
    result: stop between 2, 3 gates
    comments: 3rd gate penalty too strong

Train: lesson 4.13 Racing environment Level 2 (0.5m sensor range)
    n_envs: 20
    steps: 3 * 400000
    duration: 38min
    changes: loosen 3nd gate exceed penalty
    result: still a bit afraid of gate 3
    comments: 

Train: lesson 4.14 Racing environment Level 2 (0.5m sensor range)
    n_envs: 20
    steps: 3 * 400000
    duration: 24min
    changes: loosen 3nd gate exceed penalty
    result: low success rate, sometimes fail touching 3rd gate
    comments: 

Train: lesson 4.15 Racing environment Level 2 (0.5m sensor range)
    n_envs: 20
    steps: 3 * 400000
    duration: 24min
    changes: penalize vel for 1,2,4gate, preserve exceeding penalty
    result: better? 46% 6.39s
    comments: 

Train: lesson 4.16 Racing environment Level 0
    n_envs: 20
    steps: 20 * 500000
    duration: 142min
    changes: 10M steps in level 0 (Apparently I was too sleepy.)
    result: avg 2.99s in level 0
    comments: Ok, now we see the boundry of level 0  >_<!


Train: lesson 4.17 Racing environment Level 2 (0.5m sensor range)
    n_envs: 20
    steps: 10 * 500000
    duration: 70min
    changes: 5M steps in level 2
    result: 
    comments: 



